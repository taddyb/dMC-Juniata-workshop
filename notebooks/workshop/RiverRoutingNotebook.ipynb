{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fc22f85-a11e-4ecd-a46b-1b4c19ba0d85",
   "metadata": {},
   "source": [
    "# How to Create a Differentiable Model:\n",
    "## River Routing Notebook\n",
    "\n",
    "- Example: dMC-Juniata Routing\n",
    "- Data Location: https://doi.org/10.1029/2023WR035337"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c9af44-92fa-4057-8ee6-9abc6f1f46ec",
   "metadata": {},
   "source": [
    "## Step 1: Download the data and build our config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8751fcd-931a-467e-be26-76a17ae1284c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data already downloaded\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Create the data dir\n",
    "data_folder = Path(\"../data\")\n",
    "data_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# Change the current working directory to \"../data\"\n",
    "os.chdir(\"../data\")\n",
    "\n",
    "# Print the current working directory\n",
    "os.getcwd()\n",
    "\n",
    "# Download the routing dataset using wget and save it as 'CAMELS.zip'\n",
    "output_path = Path(\"../data/dMC-Juniata-hydroDL2\")\n",
    "if output_path.exists():\n",
    "    print(\"data already downloaded\")\n",
    "else:\n",
    "    !wget --no-check-certificate 'https://zenodo.org/records/10183429/files/dMC-Juniata-hydroDL2.zip?download=1' -O 'routing.zip'\n",
    "    !unzip 'routing.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82cfe4f-ea33-489a-9faf-aec418b42deb",
   "metadata": {},
   "source": [
    "Now go into the `dMC/conf/global_settings.yaml` file and change the `cwd` entry to your project working directory\n",
    "\n",
    "Once this is complete, we will import our functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0176a013-a0f0-4027-8ab5-35639e1b8929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taddbindas/miniconda3/envs/juniata-workshop/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Python Lib Packages\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Pypi imported Modules\n",
    "import hydra\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Putting the dMC module in the Python Path\n",
    "current_dir = Path.cwd()\n",
    "dmc_dev_path = current_dir.parents[1]\n",
    "sys.path.append(str(dmc_dev_path))\n",
    "\n",
    "# Import MLP Network\n",
    "from dMC.nn.mlp import MLP\n",
    "from dMC.nn import Initialization\n",
    "\n",
    "# Physics model\n",
    "from dMC.physics.explicit_mc import ExplicitMC\n",
    "\n",
    "# Experiment\n",
    "from dMC.experiments.train_mlp import TrainModel\n",
    "from dMC.experiments.writer import Writer\n",
    "\n",
    "# Utils functions\n",
    "from dMC.__main__ import _set_defaults\n",
    "\n",
    "# Required to generate data\n",
    "from dMC.data.datasets.nhd_srb import NHDSRB\n",
    "from dMC.data.observations.usgs import USGS\n",
    "from dMC.data.dates import Dates\n",
    "from dMC.data.normalize.min_max import MinMax\n",
    "from dMC.data import DataLoader\n",
    "\n",
    "# For evaluation\n",
    "from dMC.experiments.metrics import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e364c5a-067e-4c49-b078-f2ec680b00e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config_path = \"../../dMC/conf\"\n",
    "with hydra.initialize(config_path=config_path, version_base=\"1.3\"):\n",
    "    cfg = hydra.compose(config_name=\"global_settings.yaml\", return_hydra_config=True)\n",
    "\n",
    "cfg = _set_defaults(cfg)\n",
    "\n",
    "# Let's change the epochs to 2 so we can easily see updates\n",
    "cfg.config.experiment.epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee2a34-e937-484e-b773-6494234ff3e4",
   "metadata": {},
   "source": [
    "Now we're done! There are a lot of potential configurations, however, we are only going to focus on the MLP code today from the training against US Geological Survey Data example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b6b558-3353-4241-be94-238743b535f1",
   "metadata": {},
   "source": [
    "# Step 2: Set up your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "939f6f22-836a-429c-9d3d-9e35e88cee16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x17ac96910>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_data = cfg.config.data\n",
    "\n",
    "dates = Dates(cfg_data)  # Dates Object\n",
    "normalize = MinMax(cfg_data)  # Normalization Object\n",
    "data = NHDSRB(cfg_data, dates=dates, normalize=normalize)  # Dataset Object\n",
    "obs = USGS(cfg_data, dates, normalize)  # Observations Object\n",
    "\n",
    "# Getting the data\n",
    "hydrofabric = data.get_data()\n",
    "observations = obs.get_data().transpose(0, 1)\n",
    "\n",
    "dataloader =  DataLoader(data, obs)(cfg_data)\n",
    "dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7697952e-b527-44f1-8ceb-381d23999468",
   "metadata": {},
   "source": [
    "Let's go through this data a bit more to make things easier to understand.\n",
    "\n",
    "Below is the map of the study area, the Juniata River Basin. \n",
    "\n",
    "Unlike in most deep learning applications where we use a lumped basin prediction approach where basin attributes are averaged over a geospatial area, in distributed streamflow predictions, we have many attributes spead over a large region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494bc351-c492-4b06-83be-c50f1aa66654",
   "metadata": {},
   "source": [
    "![A map of the data](data_map.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79005772-d15f-49eb-9420-85948265e275",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "data.attributes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66d8da70-7130-4e13-a493-46dd0f1aa6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>code</th>\n",
       "      <th>fromNode</th>\n",
       "      <th>toNode</th>\n",
       "      <th>w</th>\n",
       "      <th>E</th>\n",
       "      <th>S0</th>\n",
       "      <th>AreaSqKM</th>\n",
       "      <th>TotDASqKM</th>\n",
       "      <th>AreaPerLenKM</th>\n",
       "      <th>sinuosity</th>\n",
       "      <th>ZBank</th>\n",
       "      <th>d</th>\n",
       "      <th>ComID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>r294c2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11.427123</td>\n",
       "      <td>84.892337</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>4.718534</td>\n",
       "      <td>6.384434</td>\n",
       "      <td>2.466426</td>\n",
       "      <td>1.054535</td>\n",
       "      <td>85.535748</td>\n",
       "      <td>1916.7645</td>\n",
       "      <td>8140140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>r294c3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11.427123</td>\n",
       "      <td>80.986017</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>4.718534</td>\n",
       "      <td>11.102967</td>\n",
       "      <td>2.466426</td>\n",
       "      <td>1.054535</td>\n",
       "      <td>81.618387</td>\n",
       "      <td>1916.7645</td>\n",
       "      <td>8140140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>r294c4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11.427123</td>\n",
       "      <td>78.465875</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>4.718534</td>\n",
       "      <td>15.821501</td>\n",
       "      <td>2.466426</td>\n",
       "      <td>1.054535</td>\n",
       "      <td>79.119464</td>\n",
       "      <td>1916.7645</td>\n",
       "      <td>8140140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>r294c5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>11.427123</td>\n",
       "      <td>75.953580</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>4.718534</td>\n",
       "      <td>20.540034</td>\n",
       "      <td>2.466426</td>\n",
       "      <td>1.054535</td>\n",
       "      <td>76.593397</td>\n",
       "      <td>1916.7645</td>\n",
       "      <td>8140140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>r294c6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>14.116864</td>\n",
       "      <td>74.574937</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>5.552471</td>\n",
       "      <td>26.092506</td>\n",
       "      <td>2.466426</td>\n",
       "      <td>1.167813</td>\n",
       "      <td>75.271625</td>\n",
       "      <td>1916.7645</td>\n",
       "      <td>8140002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    code  fromNode  toNode          w          E        S0  AreaSqKM  \\\n",
       "0   1  r294c2         1       2  11.427123  84.892337  0.002700  4.718534   \n",
       "1   2  r294c3         2       3  11.427123  80.986017  0.001185  4.718534   \n",
       "2   3  r294c4         3       4  11.427123  78.465875  0.001827  4.718534   \n",
       "3   4  r294c5         4       5  11.427123  75.953580  0.000624  4.718534   \n",
       "4   5  r294c6         5       6  14.116864  74.574937  0.000551  5.552471   \n",
       "\n",
       "   TotDASqKM  AreaPerLenKM  sinuosity      ZBank          d    ComID  \n",
       "0   6.384434      2.466426   1.054535  85.535748  1916.7645  8140140  \n",
       "1  11.102967      2.466426   1.054535  81.618387  1916.7645  8140140  \n",
       "2  15.821501      2.466426   1.054535  79.119464  1916.7645  8140140  \n",
       "3  20.540034      2.466426   1.054535  76.593397  1916.7645  8140140  \n",
       "4  26.092506      2.466426   1.167813  75.271625  1916.7645  8140002  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(data.cfg.csv.edges).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0ea98d-bcc0-4d53-bfa6-cce05150d7f8",
   "metadata": {},
   "source": [
    "In this example, we have a graph consisting of 583 nodes, and 10 attributes:\n",
    "- river width\n",
    "- elevation\n",
    "- slope\n",
    "- area of the river reach\n",
    "- total drainage area\n",
    "- area per length of river\n",
    "- sinousity\n",
    "- river bank height\n",
    "- River reach length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e6a198-f9b4-4cdc-8e10-0e86857cd771",
   "metadata": {},
   "source": [
    "Since these attributes have to go into a Neural Network, we will need to use a Min/Max Normalization method to scale all inputs between 0 to 1.\n",
    "\n",
    "The MinMax Scaling method is:\n",
    "```\n",
    "(X - X_min) / (X_max - X_min)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "607f14ab-2116-48f4-80d9-6880aafac32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize.scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6703cc9b-573a-43a6-bb91-4e24c1591d25",
   "metadata": {},
   "source": [
    "This data has to have a time range for training. We define that with a `Dates` object in charge of all timestamping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5af398d9-ad87-43f7-9373-021627aa717e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['02/01/2001 00:00:00', '02/01/2001 01:00:00',\n",
       "       '02/01/2001 02:00:00', ..., '03/28/2001 21:00:00',\n",
       "       '03/28/2001 22:00:00', '03/28/2001 23:00:00'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates.time_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3fb466-de3b-40e4-9160-c782a18264a8",
   "metadata": {},
   "source": [
    "Lastly, we need truth values to compare our routed results to. These come from the US Geological Survey (USGS). In this example, we are comparing to the downstream-most node for eight weeks of hourly data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad1950cd-c712-4f2f-bfca-1fe5292294c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1344, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.observations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0e95f4-a0f7-477a-a70d-3ffe7fa8fff7",
   "metadata": {},
   "source": [
    "We can package this code up together into an object that represents the \"Hydrofabric\", and then load it into a pytorch dataloader, which iterates over our dataset for training purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1084e21d-9e47-4c14-a780-7d21f93e2e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hydrofabric(attributes=tensor([[8.6940e+00, 8.1806e+01, 2.9328e-03,  ..., 8.2342e+01, 1.7706e+03,\n",
       "         4.6901e+06],\n",
       "        [8.6940e+00, 7.6588e+01, 1.9811e-03,  ..., 7.7105e+01, 1.7706e+03,\n",
       "         4.6890e+06],\n",
       "        [9.9533e+00, 7.3299e+01, 1.4209e-03,  ..., 7.3882e+01, 1.7706e+03,\n",
       "         4.6890e+06],\n",
       "        ...,\n",
       "        [1.0769e+02, 3.2069e+01, 1.7176e-04,  ..., 3.5094e+01, 1.9967e+03,\n",
       "         4.7002e+06],\n",
       "        [1.0862e+02, 3.1709e+01, 2.2679e-04,  ..., 3.4737e+01, 1.9967e+03,\n",
       "         4.7002e+06],\n",
       "        [1.0862e+02, 3.1379e+01, 1.1095e-04,  ..., 3.4406e+01, 1.9967e+03,\n",
       "         4.7001e+06]], dtype=torch.float64), forcings=tensor([[0.1149, 0.0978, 0.0627,  ..., 0.0500, 0.0428, 0.1000],\n",
       "        [0.1133, 0.0965, 0.0619,  ..., 0.0499, 0.0427, 0.0997],\n",
       "        [0.1117, 0.0951, 0.0610,  ..., 0.0497, 0.0425, 0.0994],\n",
       "        ...,\n",
       "        [0.1150, 0.0980, 0.0628,  ..., 0.0699, 0.0598, 0.1398],\n",
       "        [0.1179, 0.1004, 0.0644,  ..., 0.0724, 0.0619, 0.1446],\n",
       "        [0.1208, 0.1029, 0.0660,  ..., 0.0748, 0.0640, 0.1496]],\n",
       "       dtype=torch.float64), network=Network(gage_indices=[tensor([527, 581])], explicit_network_matrix=tensor([[ -1,  -1,  -1],\n",
       "        [  0,  -1,  -1],\n",
       "        [  1,  -1,  -1],\n",
       "        ...,\n",
       "        [521, 579,  -1],\n",
       "        [580,  -1,  -1],\n",
       "        [527, 581,  -1]]), index_graph=array([[  0,   7,  15, ..., 516, 522, 528],\n",
       "       [  1,   8,  16, ..., 517, 523, 529],\n",
       "       [  2,   9,  17, ..., 518, 524, 530],\n",
       "       ...,\n",
       "       [ -1,  -1, 579, ...,  -1,  -1,  -1],\n",
       "       [ -1,  -1, 580, ...,  -1,  -1,  -1],\n",
       "       [ -1,  -1, 581, ...,  -1,  -1,  -1]])), normalized_attributes=tensor([[8.4043e-03, 3.8417e-01, 1.8212e-01,  ..., 3.7202e-01, 7.1474e-02,\n",
       "         8.8821e-06],\n",
       "        [8.4043e-03, 3.4442e-01, 1.2301e-01,  ..., 3.3138e-01, 7.1474e-02,\n",
       "         7.7154e-06],\n",
       "        [2.0900e-02, 3.1936e-01, 8.8232e-02,  ..., 3.0636e-01, 7.1474e-02,\n",
       "         7.7671e-06],\n",
       "        ...,\n",
       "        [9.9077e-01, 5.2576e-03, 1.0666e-02,  ..., 5.3383e-03, 9.1339e-01,\n",
       "         1.9765e-05],\n",
       "        [1.0000e+00, 2.5143e-03, 1.4083e-02,  ..., 2.5678e-03, 9.1339e-01,\n",
       "         1.9765e-05],\n",
       "        [1.0000e+00, 0.0000e+00, 6.8893e-03,  ..., 0.0000e+00, 9.1339e-01,\n",
       "         1.9670e-05]]), normalized_forcings=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydrofabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4406d14e-4930-4296-a020-eef0713bb356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x177421110>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4b8c57-555a-46cb-aa43-5e0cbe5e154c",
   "metadata": {},
   "source": [
    "# Step 2: Choose your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "459ec952-3154-4c85-8301-3f31d199c79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExplicitMC(\n",
       "  (neural_network): MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=8, out_features=6, bias=True)\n",
       "      (1): Linear(in_features=6, out_features=6, bias=True)\n",
       "      (2): Linear(in_features=6, out_features=6, bias=True)\n",
       "      (3): Linear(in_features=6, out_features=2, bias=True)\n",
       "      (4): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_model = cfg.config.model\n",
    "\n",
    "neural_network = MLP(cfg=cfg_model).to(cfg_model.device)\n",
    "# neural_network = SingleParameters(cfg=cfg_model).to(cfg_model.device)\n",
    "# neural_network = Power(cfg=cfg_model).to(cfg_model.device)\n",
    "# ... etc (see imports for all options)\n",
    "\n",
    "physics_model = ExplicitMC(cfg=cfg_model, neural_network=neural_network)\n",
    "physics_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30df93f6-d318-465f-8085-a7a18bddfa0a",
   "metadata": {},
   "source": [
    "In this case, we're choosing a Multilayered Perceptron model, (MLP), coupled with the Muskingum-Cunge Equation. An MLP is a combination of Linear layers and activation functions. In our case, we use a relatively shallow MLP as:\n",
    "1. This is a very small river network\n",
    "2. We are passing in static attribute data to our model\n",
    "\n",
    "This MLP can be subsituted out for whatever you would want.\n",
    "\n",
    "Notice how the output features are 2. This means we will be predicting two variables:\n",
    "1. Manning's roughness (n)\n",
    "2. An exponential channel geometry variable (q_spatial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fcab3a-b72d-4f29-b8c5-b8e1a1452a55",
   "metadata": {},
   "source": [
    "# Step 3: Choose your experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "696117a3-6022-45cf-ae0f-9287d3d4cfc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dMC.experiments.train_mlp.TrainModel at 0x17f6d2190>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_experiment = cfg.config.experiment\n",
    "writer = Writer(cfg_experiment)\n",
    "experiment = TrainModel(cfg=cfg_experiment, writer=writer)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd6d61a-1da2-4584-ab2a-e425dc1c2242",
   "metadata": {},
   "source": [
    "We are using a class called, `Writer` so we can track metrics and statistics (using tensorboard) during the training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22ea5dbc-5aff-40cc-bc4d-91e1fa63535f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Metrics.nse of <dMC.experiments.metrics.Metrics object at 0x17f6d0e10>>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer.metrics.nse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3457648a-c5a5-43e1-9fb2-9a072462d62a",
   "metadata": {},
   "source": [
    "The experiment class is very similar to a `Trainer` function. All of the experiments have the same base class, and can be swapped depending on what we want to do (train, validate, test, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "432d22d4-79a0-4284-a199-bb38b7d52a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dMC.experiments.train_mlp.TrainModel at 0x17f6d2190>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b746d17e-f2d9-4971-a6da-3005ad03378c",
   "metadata": {},
   "source": [
    "# Step 4: Run the experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77a33c7e-da98-4f40-b0c0-15cfd74de5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1162, grad_fn=<MedianBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physics_model.neural_network.n.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef4060f7-88df-47f6-8d82-212e1c2990b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: Explicit Muskingum Cunge Routing: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1343/1343 [00:27<00:00, 48.53it/s]\n",
      "Epoch 2: Explicit Muskingum Cunge Routing: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1343/1343 [00:29<00:00, 44.83it/s]\n"
     ]
    }
   ],
   "source": [
    "experiment.run(dataloader, physics_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6998a3e0-31d7-4315-8054-dd2198639d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1370, grad_fn=<MedianBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physics_model.neural_network.n.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c30238c3-5d12-47d6-9b30-c3a574e75777",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Metrics.nse() missing 2 required positional arguments: 'predictions' and 'observations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Metrics.nse() missing 2 required positional arguments: 'predictions' and 'observations'"
     ]
    }
   ],
   "source": [
    "experiment.writer.metrics.nse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90686633-b32f-4a1e-b90d-5f8881e7db9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
